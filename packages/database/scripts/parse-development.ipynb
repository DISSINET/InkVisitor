{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Parse development book\n",
    "\n",
    "### Notebook purpose\n",
    "This notebook is development space for python parse.ts replacement and upgrade.\n",
    "It reads specified google sheets and output actants.json file, which can be imported to inkVisitor RethinkDB.py\n",
    "\n",
    "The aggreated doc for dev: https://docs.google.com/document/d/1ga6R_9TWAQlXE9XqPE_qZ2S8S8aVW2A7n8SuYpSXnoI/edit#heading=h.q9ntf0ofam2u\n",
    "The holy schema: https://app.diagrams.net/#G1bKvqEKr6JzPWryVg-vYudQy_4KvuzHS9\n",
    "\n",
    "### JSon schemas for the actants\n",
    " * are created from *.ts files through typescript-jschema commandline utility\n",
    " * the schemas are trasformed as python Classes through warlock library\n",
    "\n",
    "\n",
    "### Principles of the parsing operations\n",
    " * There are google sheet dataset, which need to be transformed to json format according to inkVisior datamodel\n",
    " * inkVisitor holds datamodel in the code, the typescript classes (see /shared/types...), or the holy schema\n",
    " * DZ created in input table parsing instructions\n",
    "   * the first 5 rows contain instructions\n",
    "   * if the keywords contain ? character, they are ignored (it is work in progress from DZ)\n",
    "\n",
    "#### Parsing instructions\n",
    " * explicit set of keywords\n",
    "   * discard\n",
    "     * ...\n",
    "   * inside\n",
    "     * the value in the column should be straitforwadly made part of the entity object, the exists update_generic method or update_fieldName mehthods for fields with custom but generally applicable logic\n",
    "   * propvalue\n",
    "     * for making so called metastatemnt or property statment (old A0093 has relation)\n",
    "     * it sits in the entity \"props\" attribute, it has IProp class\n",
    "   * special\n",
    "     * fully custom method for the parsing behavior\n",
    "     *\n",
    "\n",
    "### Parsing process\n",
    " 1. Prepare data model entities classes (from typescript inkvisitor classes -> json schema ->  python classes)\n",
    " 2. Load and wrangle all input data\n",
    " 3. Process headers of the tables for parsing instructions\n",
    " 4. Process tables row by row, column by column\n",
    " 5. Save as json file (which can be imported to the inkVisitor RethinkDB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dev updates: April\n",
    "\n",
    "## Concepts\n",
    "  * DONE wordnet_synset_id\n",
    "    * wordnet_id bounded to resource object R0067\n",
    "\n",
    "## Texts\n",
    " * DONE special_creation_event_id\n",
    "   * instructions:\n",
    "     * Create entities in this col. as new E entities, with (1) the value here as legacy_id, (2) assign (as usual) a new \"hash\" ID from the db, (3) label of this E: see next col., (4) logical type \"definite\" (default), (5) label language \"English\", (6) status \"approved\", and (7) attach to any of those Es the metaprop \"(has) - C0565 \"class\" - C2642 \"creation\" (to instantiate the event to its event type = event class).\n",
    "   * creation_event_label in standalone field\n",
    "     * this will trigger the operation\n",
    "   * lot of proptype and propvalue with non-standard schema: new branch of interpreting\n",
    "\n",
    "## Manuscripts\n",
    " * special_repository_label\n",
    "   * i:\n",
    "     * For each non-empty, non-NA, non-NS row: (1) generate L entity with label = value in this col., status = \"approved\", entity logical type = \"definite\", label language = value in the next col. (repository_label_language); (2) append to this L entity a metaprop (has) - C0565 \"class\" - C2646 \"archive or library\", and (3) under the O entity representing the row (i.e. the physical manuscript), add a metaprop which will relate this O to this L entity (repository) through the relation: O - (has) - C2645 \"repository\" - L in this col.\n",
    "   * repository_label_language\n",
    "     * i:\n",
    "       * Use this value as label language value of the repository L entity.\n",
    " * DONE creation_event_id\n",
    "   * creation_event_label\n",
    "   * i:\n",
    "     * Create entities in this col. as new E entities, with (1) the value here as legacy_id, (2) assign (as usual) a new \"hash\" ID from the db, (3) label of this E: see next col., (4) logical type \"definite\" (default), (5) label language \"English\", (6) status \"approved\", and (7) attach to any of those Es the metaprop \"(has) - C0565 \"class\" - C2642 \"creation\" (to instantiate the event to its event type = event class).\n",
    " * reproduction_online_url\n",
    "   * instructions:\n",
    "     * If non-empty, non-NA, (1) generate an R entity with label \"Reproduction of \" + label of the MS (i.e. value in the B column, status = \"approved\", label-language = \"English\", url = the URL sitting under the hyperlink value in this cell, and (2) add metaprop to the O entity represented by this row: O - (has) - C1199 \"digital reproduction\" - the R entity here generated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_tables = [\"texts\", \"manuscripts\", \"resources\", \"actions\" , \"concepts\"]\n",
    "\n",
    "#                   sheet_name,  code, header_in_row\n",
    "input_sheets = {\n",
    "    \"texts\" : (\"Texts\",\"13eVorFf7J9R8YzO7TmJRVLzIIwRJS737r7eFbH1boyE\", 5), #https://docs.google.com/spreadsheets/d/13eVorFf7J9R8YzO7TmJRVLzIIwRJS737r7eFbH1boyE/edit#gid=2056508047\n",
    "    \"manuscripts\" : (\"Manuscripts\", \"13eVorFf7J9R8YzO7TmJRVLzIIwRJS737r7eFbH1boyE\", 5),\n",
    "    \"resources\" : (\"Resources\", \"13eVorFf7J9R8YzO7TmJRVLzIIwRJS737r7eFbH1boyE\", 5),\n",
    "    \"actions\" :  (\"Statements\",\"1vzY6opQeR9hZVW6fmuZu2sgy_izF8vqGGhBQDxqT_eQ\", 5), # https://docs.google.com/spreadsheets/d/1vzY6opQeR9hZVW6fmuZu2sgy_izF8vqGGhBQDxqT_eQ/edit#gid=0\n",
    "    \"concepts\" : (\"Concepts\",\"1nSqnN6cjtdWK-y6iKZlJv4iGdhgtqkRPus8StVgExP4\", 5) # https://docs.google.com/spreadsheets/d/1nSqnN6cjtdWK-y6iKZlJv4iGdhgtqkRPus8StVgExP4/edit#gid=0\n",
    "}\n",
    "\n",
    "table_to_entity = {\n",
    "    \"concepts\" : \"IConcept\",\n",
    "    \"resources\" : \"IResource\",\n",
    "    \"texts\" : \"ITerritory\",\n",
    "    \"manuscripts\" : \"IObject\",\n",
    "    \"actions\" :  \"IAction\",\n",
    "}\n",
    "\n",
    "root_sheet_url = \"https://docs.google.com/spreadsheets/d/\"\n",
    "google_api_dotenv_path = \"../env/.env.googleapi\"  # contains google api specs for sheet access with Dator\n",
    "schema_path = '../schemas/' # path for dir with schemas\n",
    "json_schemas = {}  # holder for schemas, so they can be used for jsonschema validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# subprocess.run(\"python generate-json-schemas.py\", shell=True,capture_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os, warlock, json\n",
    "from datetime import datetime\n",
    "from jsonschema import validate\n",
    "import dissinetpytools.dator as dator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from shutil import copyfile\n",
    "\n",
    "import uuid\n",
    "\n",
    "def get_uuid_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def is_valid_uuid(val):\n",
    "    try:\n",
    "        uuid.UUID(str(val))\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# type hinting\n",
    "from collections.abc import Sequence, Callable\n",
    "from typing import List, Dict, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-02 21:46:50 : Google authentification start\n",
      "20 2022-04-02 21:46:50 : Google authentification end\n",
      "20 2022-04-02 21:46:50 : Dator initiation succesfull end\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(google_api_dotenv_path) # fills os.environ['GDRIVE_API_CREDENTIALS']\n",
    "d = dator.Dator(loglevel=10, print_log_online=True, cache=True, project_name=\"inkvisitor-import\") # expects 'GDRIVE_API_CREDENTIALS' in the global system variables (os.environ)\n",
    "d.google_authenticate()\n",
    "logger = d.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-02 21:46:50,854 INFO Class IActant available.\n",
      "2022-04-02 21:46:50,865 INFO Class IAction available.\n",
      "2022-04-02 21:46:50,874 INFO Class IConcept available.\n",
      "2022-04-02 21:46:50,885 INFO Class IEntity available.\n",
      "2022-04-02 21:46:50,896 INFO Class IEvent available.\n",
      "2022-04-02 21:46:50,903 INFO Class ILabel available.\n",
      "2022-04-02 21:46:50,912 INFO Class ILocation available.\n",
      "2022-04-02 21:46:50,921 INFO Class IObject available.\n",
      "2022-04-02 21:46:50,930 INFO Class IProp available.\n",
      "2022-04-02 21:46:50,937 INFO Class IReference available.\n",
      "2022-04-02 21:46:50,948 INFO Class IResource available.\n",
      "2022-04-02 21:46:50,960 INFO Class IStatement available.\n",
      "2022-04-02 21:46:50,970 INFO Class ITerritory available.\n",
      "2022-04-02 21:46:50,980 INFO Class IUser available.\n",
      "2022-04-02 21:46:50,990 INFO Class IValue available.\n",
      "2022-04-02 21:46:50,992 INFO There are 15 json classes available (IActant IAction IConcept IEntity IEvent ILabel ILocation IObject IProp IReference IResource IStatement ITerritory IUser IValue).\n"
     ]
    }
   ],
   "source": [
    "# read all schemas inside and warlock them as globally available classes\n",
    "schema_filenames = os.listdir(schema_path)\n",
    "json_classes = {}\n",
    "for schema in schema_filenames:\n",
    "    name = schema.split(\".\")[0]\n",
    "    file_handler = open(schema_path + schema,\"r\")\n",
    "    schema_json = json.load(file_handler)\n",
    "    json_schemas[name] = schema_json\n",
    "    globals()[name] = warlock.model_factory(schema_json)\n",
    "    json_classes[name] = globals()[name]\n",
    "    logger.info(\"Class \" + name + \" available.\")\n",
    "\n",
    "logger.info(f\"There are {len(json_classes.keys())} json classes available ({' '.join(json_classes.keys())}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:35:54,058 INFO Class IAction validated.\n",
      "2022-04-03 10:35:54,064 INFO Class IConcept validated.\n",
      "2022-04-03 10:35:54,068 INFO Class IValue validated.\n",
      "2022-04-03 10:35:54,071 INFO Class IProp validated.\n",
      "2022-04-03 10:35:54,075 INFO Class IResource validated.\n",
      "2022-04-03 10:35:54,079 INFO Class IObject validated.\n",
      "2022-04-03 10:35:54,085 INFO Class IStatement validated.\n",
      "2022-04-03 10:35:54,090 INFO Class ITerritory validated.\n",
      "2022-04-03 10:35:54,094 INFO Class ILocation validated.\n",
      "2022-04-03 10:35:54,099 INFO Class IEvent validated.\n",
      "2022-04-03 10:35:54,100 INFO Class IReference validated.\n"
     ]
    }
   ],
   "source": [
    "# factory for making entity objects, contains defaults with \"prerequisities\"\n",
    "from datetime import datetime\n",
    "import_note = \"Import batch [development] \" + str(datetime.now())\n",
    "\n",
    "class InkVisitorJSONObjectFactory:\n",
    "\n",
    "    classes = json_classes\n",
    "\n",
    "    json_class_defaults = {\n",
    "        'IAction':{\n",
    "            'class':'A', 'id':'','legacyId':'', 'label':'', 'language':'', 'detail':'','data':{'entities':{'a1':[],'a2':[],'s':[]},'valencies':{'a1':'','a2':'','s':''}}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IConcept':{\n",
    "            'class':'C', 'id':'', 'legacyId':'','label':'', 'language':'', 'detail':'','data':{}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IValue':{\n",
    "            'class':'V', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'logicalType':'4'}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IProp':{\n",
    "            'bundleEnd':False,'bundleStart':False, 'certainty':'1', 'children':[], 'elvl':'1',  'id':'', 'logic':'1', 'mood':[], 'moodvariant':'1', 'bundleOperator':'=', 'type': {'id':'','elvl':'1','logic':'1','partitivity':'1','virtuality':'1'},'value':{'id':'','elvl':'1', 'logic':'1', 'partitivity':'1', 'virtuality':'1'}\n",
    "        },\n",
    "        'IResource':{\n",
    "             'class':'R', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'url':'','partValueBaseURL':'','partValueLabel':''}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IObject':{\n",
    "             'class':'O', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'logicalType':'1'}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IStatement':{\n",
    "             'class':'S', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'actants':[], 'actions':[], 'tags':[],'territory': {'id':'','order':0}, 'text':''}, 'props':[], 'notes':[], 'status':'1','references':[]\n",
    "        },\n",
    "        'ITerritory':{\n",
    "            'class':'T', 'id':'', 'legacyId':'','label':'', 'language':'', 'detail':'','data':{'parent':{ \"id\": \"T0\", \"order\": 0 }}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'ILocation':{\n",
    "            'class':'L', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'logicalType':'1'}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IEvent':{\n",
    "            'class':'E', 'id':'', 'label':'', 'language':'', 'detail':'','data':{'logicalType':'1'}, 'props':[], 'notes':[], 'status':'1', 'references':[]\n",
    "        },\n",
    "        'IReference':{\n",
    "           'id':'','resource':'','value':''\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        for key, item in type(self).json_class_defaults.items():\n",
    "            if 'notes' in item and  len(item['notes']) == 0:\n",
    "                item['notes'].append(import_note)\n",
    "\n",
    "    def make(self, entity_name, override_object=None):\n",
    "        if override_object is None:\n",
    "            override_object = {}\n",
    "        object = type(self).json_class_defaults[entity_name]\n",
    "        object.update(override_object)\n",
    "        return type(self).classes[entity_name](deepcopy(object))\n",
    "\n",
    "    def validate_defaults(self):\n",
    "        for e in self.json_class_defaults:\n",
    "            test = self.make(e, self.json_class_defaults[e])\n",
    "            d.logger.info(f\"Class {e} validated.\")\n",
    "\n",
    "\n",
    "IOF = InkVisitorJSONObjectFactory()\n",
    "IOF.validate_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:36:34,298 INFO Calling for texts with sheet_name Texts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-03 10:36:34 : Loading dataset Texts\n",
      "20 2022-04-03 10:36:34 : Opting for variant header at row 5.\n",
      "20 2022-04-03 10:36:41 : Hyperlinks were detected and transformed in columns ['edition_1', 'edition_2', 'edition_3', 'persons_index_link', 'places_index_link'].\n",
      "20 2022-04-03 10:36:41 : Dropping empty columns in the dataset Texts : (1011, 115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:36:41,900 INFO Calling for manuscripts with sheet_name Manuscripts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-03 10:36:41 : Deleted 869 empty rows by label.\n",
      "20 2022-04-03 10:36:41 : Loaded and prepared dataset Texts : (142, 115)\n",
      "20 2022-04-03 10:36:41 : Making pickle cache of  Texts with separeted header file : (142, 115)\n",
      "20 2022-04-03 10:36:42 : Loading dataset Manuscripts\n",
      "20 2022-04-03 10:36:42 : Opting for variant header at row 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:36:46,178 INFO Calling for resources with sheet_name Resources.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-03 10:36:46 : Hyperlinks were detected and transformed in columns ['reproduction_online_url', 'reproduction_note'].\n",
      "20 2022-04-03 10:36:46 : Dropping empty columns in the dataset Manuscripts : (999, 64)\n",
      "20 2022-04-03 10:36:46 : Deleted 860 empty rows by label.\n",
      "20 2022-04-03 10:36:46 : Loaded and prepared dataset Manuscripts : (139, 64)\n",
      "20 2022-04-03 10:36:46 : Making pickle cache of  Manuscripts with separeted header file : (139, 64)\n",
      "20 2022-04-03 10:36:46 : Loading dataset Resources\n",
      "20 2022-04-03 10:36:46 : Opting for variant header at row 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:36:49,838 INFO Calling for actions with sheet_name Statements.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-03 10:36:49 : Hyperlinks were detected and transformed in columns [].\n",
      "20 2022-04-03 10:36:49 : Dropping empty columns in the dataset Resources : (1000, 21)\n",
      "20 2022-04-03 10:36:49 : Deleted 933 empty rows by label.\n",
      "20 2022-04-03 10:36:49 : Loaded and prepared dataset Resources : (67, 21)\n",
      "20 2022-04-03 10:36:49 : Making pickle cache of  Resources with separeted header file : (67, 21)\n",
      "20 2022-04-03 10:36:51 : Loading dataset Statements\n",
      "20 2022-04-03 10:36:51 : Opting for variant header at row 5.\n",
      "20 2022-04-03 10:37:08 : Hyperlinks were detected and transformed in columns [].\n",
      "20 2022-04-03 10:37:08 : Dropping empty columns in the dataset Statements : (1030, 77)\n",
      "20 2022-04-03 10:37:08 : Deleted 588 empty rows by label.\n",
      "20 2022-04-03 10:37:08 : Loaded and prepared dataset Statements : (442, 77)\n",
      "20 2022-04-03 10:37:08 : Making pickle cache of  Statements with separeted header file : (442, 77)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:37:08,365 INFO Calling for concepts with sheet_name Concepts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 2022-04-03 10:37:08 : Loading dataset Concepts\n",
      "20 2022-04-03 10:37:08 : Opting for variant header at row 5.\n",
      "20 2022-04-03 10:37:16 : Hyperlinks were detected and transformed in columns [].\n",
      "20 2022-04-03 10:37:16 : Dropping empty columns in the dataset Concepts : (3030, 66)\n",
      "20 2022-04-03 10:37:16 : Deleted 278 empty rows by label.\n",
      "20 2022-04-03 10:37:16 : Loaded and prepared dataset Concepts : (2752, 66)\n",
      "20 2022-04-03 10:37:16 : Making pickle cache of  Concepts with separeted header file : (2752, 66)\n"
     ]
    }
   ],
   "source": [
    "# empty value unifier\n",
    "def unify_empty_value(df: pd.DataFrame, empty_values=None, unified_empty_value =''):\n",
    "    if empty_values is None:\n",
    "        empty_values = ['NA', \"#N/A\", \"#VALUE!\"]\n",
    "    for naner in empty_values:\n",
    "        df = df.replace(naner,unified_empty_value)\n",
    "    df. fillna(unified_empty_value, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# load all input tables\n",
    "tables = {}\n",
    "header_infos = {}\n",
    "entity_ids = {}\n",
    "for key, sheet in input_sheets.items():\n",
    "    logger.info(f\"Calling for {key} with sheet_name {sheet[0]}.\")\n",
    "    tables[key], header_infos[key] = d.load_df_from_gsheet(sheet[0],root_sheet_url + sheet[1], sheet[0], fromCache=True, header_in_row=sheet[2], clean=True, fillna=True, cleanByColumn=\"label\", parse_hyperlink_formulas=True, numerize=False)\n",
    "    tables[key] = unify_empty_value(tables[key])\n",
    "    header_infos[key] = unify_empty_value(header_infos[key])\n",
    "\n",
    "    # code for legacyId copy and uuid creation\n",
    "    tables[key]['legacyId'] = tables[key]['id'].copy()\n",
    "    # inform instructive header about the new column and what to do with it\n",
    "    header_infos[key]['legacyId'] = \"\"\n",
    "    header_infos[key].at[3,'legacyId'] = \"inside\"\n",
    "    tables[key]['id'] = tables[key].apply(lambda x: get_uuid_id(), axis=1)  # generate unique id for each row\n",
    "    # make id dictionaries (it is much faster to search for keys there in legacyId>id retrievals)\n",
    "    ed = tables[key][[\"legacyId\",\"id\"]].set_index(\"legacyId\")\n",
    "    entity_ids[key] = ed[\"id\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "# making empty table of values\n",
    "tables['values'] = pd.DataFrame(columns=['id','value','origin'])\n",
    "tables['locations'] = pd.DataFrame(columns=['id','value','origin','legacyId'])\n",
    "tables['events'] = pd.DataFrame(columns=['id','value','origin','legacyId'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       id   label label_language label_short  \\\n0                                              \n1                                              \n2                                              \n3  inside  inside         inside     discard   \n\n                                  text_name_original  detail region_covered  \\\n0  Now concatenated with detail. Creating a new T...                          \n1                                                                             \n2                                                                             \n3                                            discard  inside        discard   \n\n  region_covered_id region_covered_label microregion_covered  ...  \\\n0                                                             ...   \n1                                                             ...   \n2                                                             ...   \n3           discard              discard             discard  ...   \n\n  dissinet_person number_defendants number_persons persons_index_link  \\\n0                                                                       \n1                                                                       \n2                                                                       \n3         discard           discard        discard            discard   \n\n  places_index_link old_genre_general old_genre_label    note  \\\n0                                                               \n1                                                               \n2                                                        note   \n3           discard           discard         discard  inside   \n\n                              parsing_rows_explained legacyId  \n0  Comment - sometimes important to read for pars...           \n1                            Source node (for props)           \n2  Prop type (for props) or further detail (for i...           \n3                                            discard   inside  \n\n[4 rows x 116 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>label_language</th>\n      <th>label_short</th>\n      <th>text_name_original</th>\n      <th>detail</th>\n      <th>region_covered</th>\n      <th>region_covered_id</th>\n      <th>region_covered_label</th>\n      <th>microregion_covered</th>\n      <th>...</th>\n      <th>dissinet_person</th>\n      <th>number_defendants</th>\n      <th>number_persons</th>\n      <th>persons_index_link</th>\n      <th>places_index_link</th>\n      <th>old_genre_general</th>\n      <th>old_genre_label</th>\n      <th>note</th>\n      <th>parsing_rows_explained</th>\n      <th>legacyId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>Now concatenated with detail. Creating a new T...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>Comment - sometimes important to read for pars...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>Source node (for props)</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>note</td>\n      <td>Prop type (for props) or further detail (for i...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>inside</td>\n      <td>inside</td>\n      <td>inside</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>inside</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>...</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>discard</td>\n      <td>inside</td>\n      <td>discard</td>\n      <td>inside</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 116 columns</p>\n</div>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_infos['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "          status                                    id                 label  \\\n0       approved  b3d223b5-5cf3-4f7e-8ec8-3f4a291355fa  abiurationem recepit   \n1       approved  7955d11f-aea5-46cb-8066-64bbea2275d9             abiuravit   \n2        pending  7071a447-0761-4ca6-8f5d-905102879c13                abluit   \n3        pending  1d07011c-9c3e-4758-be3d-882ff4cdd2f7             abscondit   \n4       approved  c041da78-db8d-482e-974f-03ad28c4b8ab           absolutus/a   \n..           ...                                   ...                   ...   \n437     approved  b87ab4a8-ae9c-49f8-9218-ae9b2f35126d               vocavit   \n438      pending  c4237a06-17e8-4fef-863d-346f1f59ccf4               vocavit   \n439     approved  4836d2cc-1563-4c70-be07-66fff634b1d7                voluit   \n440     approved  6cb981a7-7061-41a5-a87d-128e7133b7cc                 vovit   \n441  discouraged  9a3797f0-baed-4a0a-aa94-2409a255de31              warantor   \n\n                                         detail label_language  \\\n0                 received abjuration (from sb)          Latin   \n1               abjured (in front of sb - [st])          Latin   \n2                              washed away (st)          Latin   \n3                                  hid (absol.)          Latin   \n4    was absolved (by sb - [from a punishment])          Latin   \n..                                          ...            ...   \n437             summoned (sb - [concerning st])          Latin   \n438     called [to come] (sb - [concerning st])          Latin   \n439                                 wanted (st)          Latin   \n440        made a vow (to sb - [concerning st])          Latin   \n441                   guarantor (for Text part)          Latin   \n\n    subject_entity_type subject_valency subject_semantic_id  \\\n0                 P | G               1               C0146   \n1                 P | G               1               C0693   \n2                 P | G               1               C1502   \n3                 P | G               1               C1433   \n4                 P | G               1               C1447   \n..                  ...             ...                 ...   \n437               P | G               1               C1436   \n438               P | G               1        C0994 #C0428   \n439               P | G               1               C1707   \n440               P | G               1               C1648   \n441               P | G               1               C1542   \n\n                        subject_semantic_label actant1_entity_type  ...  \\\n0                                   inquisitor               P | G  ...   \n1                                         reus               P | G  ...   \n2                                      cleaner          C | S | O   ...   \n3                                    concealer                NULL  ...   \n4                                    defendant               P | G  ...   \n..                                         ...                 ...  ...   \n437                                   summoner               P | G  ...   \n438                 human interactant #inviter               P | G  ...   \n439                   one who wishes something               S | C  ...   \n440  participant in a socialy normative action               P | G  ...   \n441                                  guarantor                   T  ...   \n\n    rule_compliance_level                                       text_example  \\\n0                                                                              \n1                                                                              \n2                                                                              \n3                       O                                                      \n4                                                                              \n..                    ...                                                ...   \n437                                                                            \n438                     O                                                      \n439                                                                            \n440                        \"de quibusdam dominabus que voverunt illi sanc...   \n441                                                                            \n\n                                        recommendation  \\\n0                                                        \n1                                                        \n2                                                        \n3                                                        \n4                                                        \n..                                                 ...   \n437                                                      \n438                                                      \n439                                                      \n440                                                      \n441  Use property statement + corresponding concept...   \n\n                                                  note editor  \\\n0                                                               \n1                                                               \n2                                                               \n3                                                               \n4                                                               \n..                                                 ...    ...   \n437                                                             \n438                                                             \n439                                                             \n440                                                             \n441  The document has a date and place but the role...          \n\n    parsing_rows_explained DEPRECATED_label_with_valency_and_notes  \\\n0                                             abiurationem recepit   \n1                                                        abiuravit   \n2                                                                    \n3                                                       absconduit   \n4                                                 absolutus/a fuit   \n..                     ...                                     ...   \n437                                                        vocavit   \n438                                     vocavit (alqm - [de alqo])   \n439                                                         voluit   \n440                                                          vovit   \n441                                                       warantor   \n\n               DEPRECATED_label_english_with_valency  \\\n0    received abjuration (from sb - [concerning st])   \n1                    abjured (in front of sb - [st])   \n2                                                      \n3                                                hid   \n4      was absolved (by sb - [from some punishment])   \n..                                               ...   \n437                  summoned (sb - [concerning st])   \n438          called [to come] (sb - [concerning st])   \n439                                      wanted (st)   \n440             made a vow (to sb - [concerning st])   \n441                        guarantor (for Text part)   \n\n    DEPRECATED_action_or_relation_synonyms legacyId  \n0                                             A0168  \n1                                             A0018  \n2                                             A0428  \n3                                             A0366  \n4                                             A0214  \n..                                     ...      ...  \n437                                           A0137  \n438                                           A0404  \n439                                           A0145  \n440                                           A0202  \n441                                           A0104  \n\n[442 rows x 78 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>id</th>\n      <th>label</th>\n      <th>detail</th>\n      <th>label_language</th>\n      <th>subject_entity_type</th>\n      <th>subject_valency</th>\n      <th>subject_semantic_id</th>\n      <th>subject_semantic_label</th>\n      <th>actant1_entity_type</th>\n      <th>...</th>\n      <th>rule_compliance_level</th>\n      <th>text_example</th>\n      <th>recommendation</th>\n      <th>note</th>\n      <th>editor</th>\n      <th>parsing_rows_explained</th>\n      <th>DEPRECATED_label_with_valency_and_notes</th>\n      <th>DEPRECATED_label_english_with_valency</th>\n      <th>DEPRECATED_action_or_relation_synonyms</th>\n      <th>legacyId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>approved</td>\n      <td>b3d223b5-5cf3-4f7e-8ec8-3f4a291355fa</td>\n      <td>abiurationem recepit</td>\n      <td>received abjuration (from sb)</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C0146</td>\n      <td>inquisitor</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>abiurationem recepit</td>\n      <td>received abjuration (from sb - [concerning st])</td>\n      <td></td>\n      <td>A0168</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>approved</td>\n      <td>7955d11f-aea5-46cb-8066-64bbea2275d9</td>\n      <td>abiuravit</td>\n      <td>abjured (in front of sb - [st])</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C0693</td>\n      <td>reus</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>abiuravit</td>\n      <td>abjured (in front of sb - [st])</td>\n      <td></td>\n      <td>A0018</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pending</td>\n      <td>7071a447-0761-4ca6-8f5d-905102879c13</td>\n      <td>abluit</td>\n      <td>washed away (st)</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1502</td>\n      <td>cleaner</td>\n      <td>C | S | O</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>A0428</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pending</td>\n      <td>1d07011c-9c3e-4758-be3d-882ff4cdd2f7</td>\n      <td>abscondit</td>\n      <td>hid (absol.)</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1433</td>\n      <td>concealer</td>\n      <td>NULL</td>\n      <td>...</td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>absconduit</td>\n      <td>hid</td>\n      <td></td>\n      <td>A0366</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>approved</td>\n      <td>c041da78-db8d-482e-974f-03ad28c4b8ab</td>\n      <td>absolutus/a</td>\n      <td>was absolved (by sb - [from a punishment])</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1447</td>\n      <td>defendant</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>absolutus/a fuit</td>\n      <td>was absolved (by sb - [from some punishment])</td>\n      <td></td>\n      <td>A0214</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>437</th>\n      <td>approved</td>\n      <td>b87ab4a8-ae9c-49f8-9218-ae9b2f35126d</td>\n      <td>vocavit</td>\n      <td>summoned (sb - [concerning st])</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1436</td>\n      <td>summoner</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>vocavit</td>\n      <td>summoned (sb - [concerning st])</td>\n      <td></td>\n      <td>A0137</td>\n    </tr>\n    <tr>\n      <th>438</th>\n      <td>pending</td>\n      <td>c4237a06-17e8-4fef-863d-346f1f59ccf4</td>\n      <td>vocavit</td>\n      <td>called [to come] (sb - [concerning st])</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C0994 #C0428</td>\n      <td>human interactant #inviter</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td>O</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>vocavit (alqm - [de alqo])</td>\n      <td>called [to come] (sb - [concerning st])</td>\n      <td></td>\n      <td>A0404</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>approved</td>\n      <td>4836d2cc-1563-4c70-be07-66fff634b1d7</td>\n      <td>voluit</td>\n      <td>wanted (st)</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1707</td>\n      <td>one who wishes something</td>\n      <td>S | C</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>voluit</td>\n      <td>wanted (st)</td>\n      <td></td>\n      <td>A0145</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>approved</td>\n      <td>6cb981a7-7061-41a5-a87d-128e7133b7cc</td>\n      <td>vovit</td>\n      <td>made a vow (to sb - [concerning st])</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1648</td>\n      <td>participant in a socialy normative action</td>\n      <td>P | G</td>\n      <td>...</td>\n      <td></td>\n      <td>\"de quibusdam dominabus que voverunt illi sanc...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>vovit</td>\n      <td>made a vow (to sb - [concerning st])</td>\n      <td></td>\n      <td>A0202</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>discouraged</td>\n      <td>9a3797f0-baed-4a0a-aa94-2409a255de31</td>\n      <td>warantor</td>\n      <td>guarantor (for Text part)</td>\n      <td>Latin</td>\n      <td>P | G</td>\n      <td>1</td>\n      <td>C1542</td>\n      <td>guarantor</td>\n      <td>T</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td>Use property statement + corresponding concept...</td>\n      <td>The document has a date and place but the role...</td>\n      <td></td>\n      <td></td>\n      <td>warantor</td>\n      <td>guarantor (for Text part)</td>\n      <td></td>\n      <td>A0104</td>\n    </tr>\n  </tbody>\n</table>\n<p>442 rows × 78 columns</p>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['actions']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Declaration of controlling classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "additional_entities = []\n",
    "\n",
    "# for controlling entity and mapping of its fields\n",
    "class EntityMapper:\n",
    "\n",
    "    # simple inside values mapping from input_values in gsheets to inkVisitor enums\n",
    "    # field: { FROM  : TO }\n",
    "    enum_mapper = {'language': {\"English\":\"eng\",\"Latin\":\"lat\",\"Occitan\":\"oci\",\"Middle English\":\"enm\",\"Czech\":\"ces\",\"Italian\":\"ita\",\"French\":\"fra\",\"German\":\"deu\"},\"status\":{\"approved\":\"1\",\"pending\":\"0\",\"discouraged\":\"2\",\"warning\":\"3\"}}\n",
    "    # status  Pending = \"0\",   Approved = \"1\",  Discouraged = \"2\",  Warning = \"3\",\n",
    "    valid_entity_classes = ['A','C','E','O','R','T','P','G','S','L','NULL']\n",
    "\n",
    "\n",
    "    IOF = InkVisitorJSONObjectFactory()\n",
    "\n",
    "    def __init__(self, entity_type, data_row, logger = d.logger):\n",
    "        self.entity =  type(self).IOF.make(entity_type)\n",
    "        self.logger = logger\n",
    "        self.debug = True\n",
    "        self.data_row = data_row\n",
    "\n",
    "\n",
    "    def make_prop_object(self,prop_type_id, prop_value_id):\n",
    "        prop_object = IOF.make('IProp')\n",
    "        prop_object['id'] = get_uuid_id()\n",
    "        prop_object['type']['id'] = prop_type_id\n",
    "        prop_object['value']['id'] = prop_value_id\n",
    "        return prop_object\n",
    "\n",
    "    def make_ref_object(self, ref_resource_id, ref_value_id):\n",
    "        ref_object = IOF.make('IReference')\n",
    "        ref_object['id'] = get_uuid_id()\n",
    "        ref_object['resource'] = ref_resource_id\n",
    "        ref_object['value'] = ref_value_id\n",
    "        return ref_object\n",
    "\n",
    "    def get_entity_id(self,entity_string, origin = \"\"):\n",
    "        id = \"\"\n",
    "        # logger.info(f\"Getting entity string {entity_string} in {origin}\")\n",
    "        try:\n",
    "            if entity_string.startswith(\"C\") and entity_string[1:].isnumeric():\n",
    "                # id = tables['concepts'].loc[tables['concepts']['legacyId'] == entity_string,'id'].values[0]\n",
    "                id = entity_ids[\"concepts\"][entity_string]\n",
    "            elif entity_string.startswith(\"~V~\"):\n",
    "                ventity = self.make_ventity(entity_string, origin=origin)\n",
    "                id = ventity['id']\n",
    "            elif entity_string.startswith(\"M\") and entity_string[1:].isnumeric():\n",
    "                # id = tables['manuscripts'].loc[tables['manuscripts']['legacyId'] == entity_string,'id'].values[0]\n",
    "                id = entity_ids[\"manuscripts\"][entity_string]\n",
    "            elif entity_string.startswith(\"A\") and entity_string[1:].isnumeric():\n",
    "                # id = tables['actions'].loc[tables['actions']['legacyId'] == entity_string,'id'].values[0]\n",
    "                id = entity_ids[\"actions\"][entity_string]\n",
    "            elif entity_string.startswith(\"R\") and entity_string[1:].isnumeric():\n",
    "                # id = tables['resources'].loc[tables['resources']['legacyId'] == entity_string,'id'].values[0]\n",
    "                id = entity_ids[\"resources\"][entity_string]\n",
    "            elif entity_string.startswith(\"T\") and entity_string[1:].isnumeric():\n",
    "                # id = tables['resources'].loc[tables['resources']['legacyId'] == entity_string,'id'].values[0]\n",
    "                id = entity_ids[\"texts\"][entity_string]\n",
    "\n",
    "            elif is_valid_uuid(entity_string):\n",
    "                id = entity_string\n",
    "\n",
    "        except IndexError as E:\n",
    "            logger.info(f\"Cannot get entity id from entity string {entity_string} in {origin}. {E}\")\n",
    "\n",
    "        if id != \"\" and isinstance(id, str):\n",
    "            # logger.info(f\"Got entity id {id} from entity string {entity_string} in {origin}\")\n",
    "            return id\n",
    "        else:\n",
    "            logger.error(f\"Cannot get entity id from {entity_string}.\")\n",
    "            raise Exception(f\"Cannot get entity id from {entity_string}.\")\n",
    "\n",
    "    def make_ventity(self, value_string, origin=\"\"):\n",
    "        # logger.info(f\"Generating ventity from {value_string}.\")\n",
    "        # generate value entity object...\n",
    "        ventity = IOF.make('IValue')\n",
    "        ventity['id'] = get_uuid_id()\n",
    "        ventity['label'] = value_string.replace(\"~V~\",\"\")\n",
    "\n",
    "        if self.debug:\n",
    "            ventity['notes'].append(origin)\n",
    "\n",
    "        # register ventity\n",
    "        tables['values'] = tables['values'].append({'id':ventity['id'] ,'value':ventity['label'],\"origin\":origin},ignore_index=True )\n",
    "        additional_entities.append(ventity)\n",
    "\n",
    "        # logger.info(f\"Ventity id={ventity['id']} generated.\")\n",
    "\n",
    "        return ventity\n",
    "\n",
    "    def make_rentity(self, label, url = \"\", origin=\"\"):\n",
    "        # logger.info(f\"Generating rentity from {value_string}.\")\n",
    "        # generate resource entity object...\n",
    "        rentity = IOF.make('IResource')\n",
    "        rentity['id'] = get_uuid_id()\n",
    "        rentity['label'] = label\n",
    "        rentity['data']['link'] = url\n",
    "\n",
    "        if self.debug:\n",
    "            rentity['notes'].append(origin)\n",
    "\n",
    "        # register rentity\n",
    "        tables['resources'] = tables['resources'].append({'id':rentity['id'] ,'value':rentity['label'],\"origin\":origin}, ignore_index=True )\n",
    "        additional_entities.append(rentity)\n",
    "\n",
    "        # logger.info(f\"Rentity id={rentity['id']} generated.\")\n",
    "        return rentity\n",
    "\n",
    "\n",
    "    def make_eentity(self, label, legacyId, url = \"\", origin=\"\"):\n",
    "\n",
    "        eentity = IOF.make('IEvent')\n",
    "        eentity['id'] = get_uuid_id()\n",
    "        eentity['label'] = label\n",
    "        eentity['legacyId'] = legacyId\n",
    "\n",
    "        if self.debug:\n",
    "            eentity['notes'].append(origin)\n",
    "\n",
    "        # register event\n",
    "        tables['events'] = tables['events'].append({'id':eentity['id'] ,'value':eentity['label'],\"origin\":origin, \"legacyId\":legacyId}, ignore_index=True )\n",
    "        additional_entities.append(eentity)\n",
    "\n",
    "        return eentity\n",
    "\n",
    "    def make_lentity(self, label, legacyId=\"\", url = \"\", origin=\"\"):\n",
    "\n",
    "        lentity = IOF.make('ILocation')\n",
    "        lentity['id'] = get_uuid_id()\n",
    "        lentity['label'] = label\n",
    "        lentity['legacyId'] = legacyId\n",
    "\n",
    "        if self.debug:\n",
    "            lentity['notes'].append(origin)\n",
    "\n",
    "        # register lentity\n",
    "        tables['locations'] = tables['locations'].append({'id':lentity['id'] ,'value':lentity['label'],\"origin\":origin,\"legacyId\":legacyId}, ignore_index=True )\n",
    "        additional_entities.append(lentity)\n",
    "\n",
    "        return lentity\n",
    "\n",
    "    # interprets prop_type (should be always concept or resource) and input_value (should be concept or value string)\n",
    "    # get ids of the prop_type and prop_value (possibly creates and register values object)\n",
    "    # make iProp object\n",
    "    # puts iProp object into the entity props property\n",
    "    def hook_prop_object(self, prop_type, input_value, prop_source=\"\",  origin=\"\"):\n",
    "\n",
    "        # allowed entities in type\n",
    "        assert \"C\" in prop_type[0] or \"R\" in prop_type[0], f\"Prop type unknown, C or R string entity expected? {prop_type}, {origin}\"\n",
    "\n",
    "        # allowed entities in input\n",
    "        allowed_strict_entities = ['C','M','A','E','L','R','S','V','O','T'] # should be followed by numbers\n",
    "        allowed_free_string_entities = ['~V~']\n",
    "\n",
    "        # checking input_value\n",
    "        if not is_valid_uuid(input_value):\n",
    "            if any(input_value.startswith(c)for c in allowed_strict_entities):\n",
    "                # check for numbers\n",
    "                if not input_value[1:].isnumeric():\n",
    "                    input_value = \"~V~\"+input_value\n",
    "            elif not any(input_value.startswith(c)for c in allowed_free_string_entities):\n",
    "                input_value = \"~V~\"+input_value\n",
    "\n",
    "        # TODO this is useless now, because the line above will make ~V~ from everything uknown\n",
    "        assert any(input_value.startswith(c)  for c in allowed_strict_entities) or any(input_value.startswith(c)  for c in allowed_free_string_entities) or is_valid_uuid(input_value), f\"Prop value unknown, C string or V string entity expected, or valid uuid.{input_value}, {origin}\"\n",
    "\n",
    "        prop_type_id = self.get_entity_id(prop_type, origin=origin)\n",
    "        if not is_valid_uuid(input_value):\n",
    "            prop_value_id = self.get_entity_id(input_value, origin=origin)\n",
    "        else:\n",
    "            prop_value_id = input_value\n",
    "        # logger.info(f\"{prop_type_id}, {prop_value_id}\")\n",
    "\n",
    "        # make IProp object\n",
    "        prop_object = self.make_prop_object(prop_type_id, prop_value_id)\n",
    "\n",
    "        if prop_source !=\"\": # means propvalue_2nd\n",
    "            self.hook_2ndprop_into_props(prop_object,prop_source)\n",
    "            pass\n",
    "        else:\n",
    "            # hook directly into the entity object\n",
    "            self.hook_prop_into_props(prop_object)\n",
    "\n",
    "    def hook_ref_object(self, ref_legacyID, input_value, prop_source=\"\",  origin=\"\"):\n",
    "\n",
    "        # allowed entities in ref_legacyID\n",
    "        assert \"R\" in ref_legacyID, f\"Unknown input, R legacyId expected? {ref_legacyID}, {origin}\"\n",
    "\n",
    "        #modify value, so the value object is created\n",
    "        input_value = \"~V~\"+input_value\n",
    "\n",
    "        ref_resource_id = self.get_entity_id(ref_legacyID, origin=origin)\n",
    "        ref_value_id = self.get_entity_id(input_value, origin=origin)\n",
    "\n",
    "        # make IReference object\n",
    "        ref_object = self.make_ref_object(ref_resource_id, ref_value_id)\n",
    "\n",
    "        self.hook_ref_into_refs(ref_object)\n",
    "\n",
    "\n",
    "    def hook_prop_into_props(self,prop_object):\n",
    "        self.entity['props'].append(prop_object)\n",
    "\n",
    "    def hook_ref_into_refs(self,ref_object):\n",
    "        self.entity['references'].append(ref_object)\n",
    "\n",
    "    def hook_2ndprop_into_props(self,prop_object,fst_prop_identification):  # identification by concept id\n",
    "        key = 0\n",
    "        keyId = self.get_entity_id(fst_prop_identification)\n",
    "        assert len(keyId)>0, f\"Cannot recognize entity id from {fst_prop_identification}\"\n",
    "\n",
    "        # count, value in enumerate(values)\n",
    "        for count, po in enumerate(self.entity['props']):\n",
    "            if po['type']['id'] == keyId and len(po['children']) == 0:  # I am counting on the fact, that if there relations from multiples, they are processed in the specific right order\n",
    "               po['children'].append(prop_object)\n",
    "\n",
    "    # method invoker for the INSIDE operation with concrete fields\n",
    "    def update_inside_field(self, field_name, input_value, origin= \"\"):\n",
    "        if input_value != '':\n",
    "\n",
    "            if (\"#\" in input_value or \"~\" in input_value) and field_name!= \"note\" and \"https://docs.\" not in input_value:\n",
    "                self.logger.info(f\"ALERT # or ~ in the input value {input_value}\")\n",
    "\n",
    "            update_operation = \"update_\" + field_name\n",
    "            update_func = getattr(self, update_operation, self.update_generic)\n",
    "            update_func(field_name, input_value, origin)\n",
    "        else:\n",
    "            raise Exception(f\"Trying to update {field_name} with empty input value.\")\n",
    "\n",
    "    #########################################################################################################\n",
    "    # the naming of procedures corresponds to the name of the input_table fields,  used for inside operations\n",
    "\n",
    "    def update_label_language(self, field_name, input_value, origin = \"\"):\n",
    "        if input_value in type(self).enum_mapper['language']:\n",
    "            self.entity['language'] = type(self).enum_mapper['language'][input_value]\n",
    "        else:\n",
    "            self.logger.error(f\"Unable to set language in {origin}.\")\n",
    "            self.entity['language'] = input_value # will raise error\n",
    "\n",
    "    def update_status(self, field_name, input_value, origin = \"\"):\n",
    "        if input_value in type(self).enum_mapper['status']:\n",
    "            self.entity['status'] = type(self).enum_mapper['status'][input_value]\n",
    "        else:\n",
    "            self.logger.error(f\"Unable to set status in {origin}.\")\n",
    "            self.entity['status'] = input_value # will raise error\n",
    "\n",
    "    def update_note(self, field_name, input_value, origin = \"\"):\n",
    "        #self.logger.info(f\"Updating note with {input_value}.\")\n",
    "        if \"#\" in input_value:\n",
    "            values = [v.strip() for v in input_value.split(\"#\")]\n",
    "            for v in values:\n",
    "                self.entity['notes'].append(v)\n",
    "        else:\n",
    "            self.entity['notes'].append(input_value)\n",
    "\n",
    "    def update_id(self, field_name, input_value, origin = \"\"):\n",
    "        # self.entity['id'] = input_value\n",
    "        self.entity['id'] = input_value\n",
    "\n",
    "    def update_legacyId(self, field_name, input_value, origin = \"\"):\n",
    "        # logger.info(f\"Trying to set legacyId {type(input_value)}:'{input_value}' {origin}.\")\n",
    "        self.entity['legacyId'] = input_value\n",
    "\n",
    "    def update_label(self, field_name, input_value, origin = \"\"):\n",
    "        self.entity['label'] = input_value\n",
    "\n",
    "    def update_wordnet_lemma_id(self, field_name, input_value, origin = \"\"):\n",
    "        # self.logger.info(f\" wordnet_lemma_id NOT IMPLEMENTED \")\n",
    "        pass\n",
    "\n",
    "    def update_wordnet_synset_id(self, field_name, input_value, origin = \"\"):\n",
    "        # self.logger.info(f\" wordnet_synset_id NOT IMPLEMENTED \")\n",
    "        pass\n",
    "\n",
    "    def update_generic(self, field_name, input_value, origin = \"\"):\n",
    "        self.entity[field_name] = input_value\n",
    "\n",
    "\n",
    "\n",
    "class TerritoryEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "class ConceptEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "class ActionEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger,):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "    def update_subject_entity_type(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: subject_entity_type\")\n",
    "        entities = [e.strip() for e in value.split(\"|\")]\n",
    "        for e in entities:\n",
    "            if e in self.valid_entity_classes:\n",
    "                self.entity['data']['entities']['s'].append(e)\n",
    "            elif e == \"*\":\n",
    "                self.entity['data']['entities']['s'] = self.valid_entity_classes\n",
    "            else:\n",
    "                logger.error(f\"Non valid entity processed: {e} while AP.update_subject_entity_type().\")\n",
    "\n",
    "    def update_subject_valency(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: subject_valency\")\n",
    "        self.entity['data']['valencies']['s'] = value\n",
    "\n",
    "    def update_actant1_entity_type(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: actant1_entity_type\")\n",
    "        entities = [e.strip() for e in value.split(\"|\")]\n",
    "        for e in entities:\n",
    "            if e in self.valid_entity_classes:\n",
    "                self.entity['data']['entities']['a1'].append(e)\n",
    "            elif e == \"*\":\n",
    "                self.entity['data']['entities']['a1'] = self.valid_entity_classes\n",
    "            else:\n",
    "                logger.error(f\"Non valid entity processed: {e} while AP.update_actant1_entity_type().\")\n",
    "\n",
    "    def update_actant2_entity_type(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: actant2_entity_type\")\n",
    "        entities = [e.strip() for e in value.split(\"|\")]\n",
    "        for e in entities:\n",
    "            if e in self.valid_entity_classes:\n",
    "                self.entity['data']['entities']['a2'].append(e)\n",
    "            elif e == \"*\":\n",
    "                self.entity['data']['entities']['a2'] = self.valid_entity_classes\n",
    "            else:\n",
    "                logger.error(f\"Non valid entity processed: {e} while AP.update_actant2_entity_type().\")\n",
    "\n",
    "    def update_actant1_valency(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: actant1_valency\")\n",
    "        self.entity['data']['valencies']['a1'] = value\n",
    "\n",
    "    def update_actant2_valency(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: actant1_valency\")\n",
    "        self.entity['data']['valencies']['a2'] = value\n",
    "\n",
    "\n",
    "class ResourceEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "    def update_url(self, operation, value, entity_mapper):\n",
    "        # self.logger.info(f\"AP custom field: subject_entity_type\")\n",
    "        self.entity['data']['url'] = value\n",
    "\n",
    "\n",
    "class ObjectEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "class EventEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "class LocationEntityMapper(EntityMapper):\n",
    "    def __init__(self,entity_type, data_row, logger = d.logger):\n",
    "        EntityMapper.__init__(self,entity_type, data_row, logger)\n",
    "\n",
    "\n",
    "class EntityMapperFactory:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def make(self, entity_name, data_row):\n",
    "        if 'ITerritory' == entity_name:\n",
    "            return TerritoryEntityMapper(entity_name, data_row)\n",
    "        elif 'IAction' == entity_name:\n",
    "            return ActionEntityMapper(entity_name, data_row)\n",
    "        elif 'IConcept' == entity_name:\n",
    "            return ConceptEntityMapper(entity_name,data_row)\n",
    "        elif 'IResource' == entity_name:\n",
    "            return ResourceEntityMapper(entity_name, data_row)\n",
    "        elif 'IObject' == entity_name:\n",
    "            return ObjectEntityMapper(entity_name, data_row)\n",
    "        elif 'IEvent' == entity_name:\n",
    "            return EventEntityMapper(entity_name, data_row)\n",
    "        elif 'ILocation' == entity_name:\n",
    "            return LocationEntityMapper(entity_name, data_row)\n",
    "\n",
    "        else:\n",
    "            logger.warning(f\"Unrecognized entity class in entity mapper. Is this right?\")\n",
    "            return EntityMapper(entity_name)\n",
    "\n",
    "\n",
    "# CONTROL CLASS\n",
    "class ParseController():\n",
    "\n",
    "    def __init__(self, entity_list: [], keyword_row_id = 3,  logger = d.logger):\n",
    "        self.entity_list = entity_list\n",
    "        self.logger = logger\n",
    "        self.parsers = {}\n",
    "        self.js_objects = []\n",
    "\n",
    "        for e in self.entity_list:\n",
    "            if 'texts' in e:\n",
    "                self.parsers[e] = TextParser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "            elif 'actions' in e:\n",
    "                self.parsers[e] = ActionParser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "            elif 'concepts' in e:\n",
    "                self.parsers[e] = ConceptParser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "            elif 'resources' in e:\n",
    "                self.parsers[e] = ResourceParser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "            elif 'manuscripts' in e:\n",
    "                self.parsers[e] = ManuscriptParser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "            else:\n",
    "                self.logger.warning(f\"Coming to basic Parser entity - strange '{e}' {type(e)}.\")\n",
    "                self.parsers[e] = Parser(e, header_df = header_infos[e], table_df = tables[e], keyword_row_id = keyword_row_id, logger = logger)\n",
    "\n",
    "    def load_json_objects(self):\n",
    "        for name, p in self.parsers.items():\n",
    "            self.js_objects = self.js_objects + p.js_objects\n",
    "\n",
    "    def parse(self):\n",
    "        for name, p in self.parsers.items():\n",
    "            p.parse_rows()\n",
    "\n",
    "\n",
    "# WORKER CLASS\n",
    "class Parser():\n",
    "    EMP = EntityMapperFactory()\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        self.name = name\n",
    "        self.logname = name.upper()\n",
    "        self.input_header_df = header_df\n",
    "        self.input_table_df = table_df\n",
    "        self.prepared_table = pd.DataFrame()\n",
    "        self.keyword_row_id =  keyword_row_id\n",
    "        self.columns = self.input_header_df.columns.tolist()\n",
    "\n",
    "        self.parsing_instruction = {}\n",
    "        self.oper_columns = {'discard':[],'inside':[],'special':[],'unknown':[],'propvalue':[],'propvalue_2nd':[],\"dependent\":[],\"proptype\":[]}\n",
    "        self.logger = logger\n",
    "\n",
    "        # parsed json data holder\n",
    "        self.js_objects = []\n",
    "\n",
    "        # RUN\n",
    "        self.process_header_instructions()\n",
    "        self.prepare_input_table()\n",
    "\n",
    "    # \"parsing\" instructions\n",
    "    def process_header_instructions(self) -> (pd.DataFrame, pd.DataFrame):\n",
    "        keyword_row = self.input_header_df.iloc[self.keyword_row_id]\n",
    "        prop_type_row = self.input_header_df.iloc[self.keyword_row_id - 1]\n",
    "        source_node_row = self.input_header_df.iloc[self.keyword_row_id - 2]\n",
    "\n",
    "        log_uncertain_instructions = []\n",
    "\n",
    "        for c in self.columns:\n",
    "            instruction_candidate = str(keyword_row.at[c]).strip()\n",
    "            prop_type_candidate = str(prop_type_row.at[c]).strip()\n",
    "            source_node_candidate = str(source_node_row.at[c]).strip()\n",
    "\n",
    "            if c == '':\n",
    "                self.logger.error(f\"{self.logname} There is empty column in the dataset.\")\n",
    "                raise Exception(f\"{self.logname} There is empty column in the dataset.\")\n",
    "\n",
    "            if \"?\" in instruction_candidate or \"?\" in prop_type_candidate or \"?\" in source_node_candidate:\n",
    "                log_uncertain_instructions.append(f\"{c.upper()}:{instruction_candidate},{prop_type_candidate},{source_node_candidate}\")\n",
    "                instruction  = {'operation':'discard', 'target': None}\n",
    "                self.oper_columns['discard'].append(c)\n",
    "\n",
    "\n",
    "            # known instructions\n",
    "            if 'discard' in instruction_candidate:\n",
    "                instruction  = {'operation':'discard', 'target': None}\n",
    "                self.oper_columns['discard'].append(c)\n",
    "\n",
    "            elif 'propvalue' ==  instruction_candidate:\n",
    "                prop_type = prop_type_candidate\n",
    "                source_node = source_node_candidate\n",
    "\n",
    "                # test whether is its propvalue proper or dependent (=proptype is dynamic, value from another column)\n",
    "                if prop_type.strip() == \"\":\n",
    "                    self.oper_columns['dependent'].append(c)\n",
    "                    continue # ignoring \"dependent propvalue\"\n",
    "\n",
    "                if \"?\" in prop_type or \"?\"  in source_node:\n",
    "                    instruction = {'operation':'unknown', 'target': None}\n",
    "                    self.oper_columns['unknown'].append(c)\n",
    "                else:\n",
    "                    instruction  = {'operation':'propvalue', 'type': prop_type, 'source':source_node} # source can be ignored, because the iProp object is sitting inside of it\n",
    "                    self.oper_columns['propvalue'].append(c)\n",
    "\n",
    "            elif 'propvalue_2nd' in instruction_candidate:\n",
    "                prop_type = prop_type_candidate\n",
    "                source_node = source_node_candidate\n",
    "                if \"?\" in prop_type or \"?\"  in source_node:\n",
    "                    instruction = {'operation':'unknown', 'target': None}\n",
    "                    self.oper_columns['unknown'].append(c)\n",
    "                else:\n",
    "                    instruction  = {'operation':'propvalue_2nd', 'type': prop_type, 'source':source_node} # source can NOT be ignored, it signals which existing iProp object will hold this iProp object\n",
    "                    self.oper_columns['propvalue_2nd'].append(c)\n",
    "\n",
    "            elif 'special' in instruction_candidate:\n",
    "                # looks for custom functions registered by column name\n",
    "                prop_type = prop_type_candidate\n",
    "                source_node = source_node_candidate\n",
    "                instruction  = {'operation':'special', 'type': prop_type, 'source':source_node}\n",
    "                self.oper_columns['special'].append(c)\n",
    "\n",
    "            elif 'proptype' in instruction_candidate:\n",
    "                instruction  = {'operation':'proptype', 'type': prop_type, 'source':source_node}\n",
    "                #logger.info(f\"here ...{instruction_candidate} {c}\")\n",
    "                self.oper_columns['proptype'].append(c)\n",
    "\n",
    "            elif 'dependent' in instruction_candidate:\n",
    "                # ignore\n",
    "                # the value is solved by another instruction\n",
    "                instruction  = {'operation':'dependent', 'type': prop_type, 'source':source_node}\n",
    "\n",
    "            elif 'inside' in instruction_candidate:\n",
    "                if \"?\" in c:\n",
    "                    instruction = {'operation':'unknown', 'target': None}\n",
    "                    self.oper_columns['unknown'].append(c)\n",
    "                else:\n",
    "                    instruction  = {'operation':'inside', 'target': None}\n",
    "                    if len(prop_type_candidate) > 0:\n",
    "                        instruction  = {'operation':'inside', 'target': prop_type_candidate}\n",
    "\n",
    "                    self.oper_columns['inside'].append(c)\n",
    "\n",
    "            else:\n",
    "                instruction = {'operation':'unknown', 'target': None}\n",
    "                self.oper_columns['unknown'].append(c)\n",
    "            self.parsing_instruction[c] = instruction\n",
    "\n",
    "        self.logger.info(f\"{self.logname} Uncertain parsing instructions in {len(log_uncertain_instructions)} columns: \" + \" \".join(log_uncertain_instructions) + \".\")\n",
    "        return self.parsing_instruction\n",
    "\n",
    "    def prepare_input_table(self):\n",
    "        ip = self.input_table_df.copy()\n",
    "\n",
    "        # discard  columns with discard and unknown operations\n",
    "        ip.drop(columns=self.oper_columns['discard']+self.oper_columns['unknown'], inplace=True)\n",
    "\n",
    "        self.logger.info(f\"{self.logname} {len(self.oper_columns['discard']+self.oper_columns['unknown'])} columns have been dropped (discard:{len(self.oper_columns['discard'])}, unknown:{len(self.oper_columns['unknown'])}). Table now has {len(ip.columns)} columns, inside:{len(self.oper_columns['inside'])},propvalue:{len(self.oper_columns['propvalue'])}, special:{len(self.oper_columns['special'])}, proptype: {len(self.oper_columns['proptype'])}, dependent:{len(self.oper_columns['dependent'])}. Originally {self.input_table_df.shape[1]} columns.\")\n",
    "\n",
    "        self.prepared_table = ip\n",
    "\n",
    "\n",
    "    def prepare_property(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def make_row_object(self, data_row):\n",
    "        class_name = table_to_entity[self.name]\n",
    "        return self.EMP.make(class_name, data_row)\n",
    "\n",
    "    def itemize_valuestring_for_multiples(self, value_with_multiples, origin=\"\") -> []:\n",
    "        values = []\n",
    "        if isinstance(value_with_multiples,str):\n",
    "            parsed_value = value_with_multiples.split('#')\n",
    "            values =  [item.strip() for item in parsed_value]\n",
    "        else:\n",
    "            raise Exception(f\"Expected value to be string. Got {type(value_with_multiples)}. {origin}\")\n",
    "        return values\n",
    "\n",
    "    def parse_rows(self):\n",
    "        self.logger.info(f\"Starting to parse {self.name}.\")\n",
    "\n",
    "        if  self.prepared_table['label'].isnull().any():\n",
    "            self.prepared_table  = self.prepared_table[self.prepared_table['label'].notna()]\n",
    "            self.logger.info(f\"Empty labels found in {self.name} table. (new entities added through parsing process). Adjusting.\")\n",
    "\n",
    "        for key, row in self.prepared_table.iterrows():\n",
    "            # self.logger.info(f\"{self.name} Processing row {key}\")\n",
    "            entity_mapper = self.make_row_object(row.to_dict())\n",
    "\n",
    "            for name, value in row.items():\n",
    "                if name in self.parsing_instruction:\n",
    "                    operation = self.parsing_instruction[name]\n",
    "                else:\n",
    "                    continue # silently ignore unknown columns\n",
    "                # logger.info(f\"{self.name} Processing columns {name}, with value {value}. Op:{operation}\")\n",
    "\n",
    "                # force string\n",
    "                value = str(value)\n",
    "\n",
    "                if operation['operation'] == 'inside' and value != '' and '?' not in name:\n",
    "                    # logger.info(f\"{self.name} Processing columns {name}, with value {value}. Op:{operation}\")\n",
    "                    if operation['target']:\n",
    "                        name = operation['target']\n",
    "                    entity_mapper.update_inside_field(name,value,operation['operation'] +\">\"+ str(key)+\":\"+str(name)+\":\"+str(value))\n",
    "\n",
    "                if operation['operation'] == 'propvalue' and value != '':\n",
    "                    # logger.info(f\"{self.name} Processing columns {name}, with value {value}. Op:{operation}\")\n",
    "                    prop_type = operation['type']\n",
    "                    if prop_type == '' or 'C' not in prop_type:\n",
    "                        raise Exception(f\"Propvalue does not have prop type defined. C entity-string expected, got {key}, {name}, {value}\")\n",
    "                    for item in self.itemize_valuestring_for_multiples(value):\n",
    "                        entity_mapper.hook_prop_object(prop_type = prop_type, input_value = item, origin = operation['operation'] +\">\"+ str(key)+\":\"+str(name)+\":\"+str(value))\n",
    "\n",
    "                if operation['operation'] == 'propvalue_2nd' and value != '':\n",
    "                    # logger.info(f\"{self.name} Processing columns {name}, with value {value}. Op:{operation}\")\n",
    "                    prop_type = operation['type']\n",
    "                    prop_source_name = operation['source']  # header_name,  we need concept_id\n",
    "\n",
    "                    prop_source_id = self.parsing_instruction[prop_source_name]['type']\n",
    "                    assert 'C' in prop_source_id, f\"Trying to get to the concept of 1st level property to adress 2nd level property.\"\n",
    "\n",
    "                    if prop_type == '' or 'C' not in prop_type:\n",
    "                        raise Exception(f\"Propvalue does not have prop type defined. C entity-string expected, got {key}, {name}, {value}\")\n",
    "\n",
    "                    origin = operation['operation'] +\">\"+ str(key)+\":\"+str(name)+\":\"+str(value)\n",
    "\n",
    "                    for item in self.itemize_valuestring_for_multiples(value, origin=origin):\n",
    "                        entity_mapper.hook_prop_object(prop_type = prop_type, input_value = item, prop_source = prop_source_id, origin = origin)\n",
    "                    pass\n",
    "\n",
    "                if operation['operation'] == 'special' and value != \"\":\n",
    "                    # logger.info(f\"SPECIAL {operation} {value}\")\n",
    "                    func = getattr(self, 'special_'+name)\n",
    "                    func(operation, value, entity_mapper)\n",
    "\n",
    "            self.js_objects.append(entity_mapper.entity)\n",
    "            # break  DEV, checking parsing after first iteration\n",
    "\n",
    "\n",
    "    def special_editor(self, operation, value, entity_mapper, field_name=\"special_editor\"):\n",
    "        pass\n",
    "\n",
    "\n",
    "class TextParser(Parser):\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        Parser.__init__(self, name, header_df, table_df, keyword_row_id, logger)\n",
    "\n",
    "    # special methods for fields, which needs fully individual processing\n",
    "    def special_edition_1(self, operation, value, entity_mapper, field_name=\"special_edition1\", ):\n",
    "        # Parse this col. as \"propvalue\" - but you need to generate the target entities since they do not exist. How to do it: for any value, create an R entity with \"label\" = textual value in this col., \"label language\" = English, \"status\" = \"approved\", and \"URL\" = the hyperlink in the formula sitting on the textual value in this col. As usual, ignore NS and NA values (exact match) - do not import anything if the value is NA.\n",
    "        # logger.info(f\"Special edition1 running ...{operation} {value}\")\n",
    "\n",
    "        origin = operation['operation'] +\" \"+ operation['type']+ \">\"+ \":\"+field_name + str(value)\n",
    "        prop_type = operation['type']\n",
    "\n",
    "        # make rentity\n",
    "        # logger.info(f\"Rentity making {value}\")\n",
    "        if \"|\" in value:\n",
    "            data = value.split(\"|\")\n",
    "            label = data[0]\n",
    "            url = data[1]\n",
    "        else:\n",
    "            url = \"\"\n",
    "            label = value\n",
    "            # logger.warning(f\"Expected char | signaling url after label. Got just {value}.\"+origin)\n",
    "\n",
    "        rentity = entity_mapper.make_rentity(label, url, origin=origin)\n",
    "\n",
    "        entity_mapper.hook_prop_object(prop_type = prop_type, input_value = rentity['id'], origin = origin)\n",
    "\n",
    "    def special_edition_2(self, operation, value, entity_mapper):\n",
    "        self.special_edition_1( operation, value, entity_mapper, field_name=\"edition_2\")\n",
    "\n",
    "    def special_edition_3(self, operation, value, entity_mapper):\n",
    "        self.special_edition_1( operation, value, entity_mapper, field_name=\"edition_3\")\n",
    "\n",
    "    def special_creation_event_id(self, operation, value, entity_mapper : EntityMapper, field_name=\"creation_event_id\"):\n",
    "        # Create entities in this col. as new E entities, with (1) the value here as legacy_id, (2) assign (as usual) a new “hash” ID from the db, (3) label of this E: see next col., (4) logical type “definite” (default), (5) label language “English”, (6) status “approved”, and (7) attach to any of those Es the metaprop \"(has) - C0565 “class” - C2642 “creation” (to instantiate the event to its event type = event class).\n",
    "\n",
    "        origin = operation['operation'] +\">\"+ \":\"+field_name + str(value)\n",
    "\n",
    "        data = entity_mapper.data_row\n",
    "        event_entity = entity_mapper.make_eentity(data['creation_event_label'], legacyId = value, origin = origin)\n",
    "\n",
    "        prop_type_id = entity_mapper.get_entity_id(\"C0565\")\n",
    "        prop_value_id = entity_mapper.get_entity_id(\"C2642\")\n",
    "\n",
    "        # make IProp object\n",
    "        prop_object = entity_mapper.make_prop_object(prop_type_id, prop_value_id)\n",
    "\n",
    "\n",
    "        # hook prop object to the event entity\n",
    "        event_entity['props'].append(prop_object)\n",
    "\n",
    "        # hook the vent event to the territory\n",
    "        entity_mapper.hook_prop_object(prop_type = \"C2642\", input_value = event_entity['id'], origin = origin)\n",
    "\n",
    "        # process time_relations\n",
    "        t_relations = [(\n",
    "            data[\"timerelation1_type_conceptified_id\"], data[\"timerelation1_target_id\"]\n",
    "        ), (\n",
    "            data[\"timerelation2_type_conceptified_id\"], data[\"timerelation2_target_id\"]\n",
    "        ),(\n",
    "            data[\"timerelation3_type_conceptified_id\"], data[\"timerelation3_target_id\"]\n",
    "        ), (\n",
    "            data[\"timerelation4_type_conceptified_id\"], data[\"timerelation4_target_id\"]\n",
    "        )]\n",
    "\n",
    "        origin = data['legacyId']\n",
    "        for o in t_relations:\n",
    "            if len(o[0]) > 0 and len(o[1]) > 0:\n",
    "                prop_type_id = entity_mapper.get_entity_id(o[0], origin = origin)\n",
    "                prop_value_id = entity_mapper.get_entity_id(\"~V~\"+o[1], origin = origin)\n",
    "                prop_object = entity_mapper.make_prop_object(prop_type_id, prop_value_id)\n",
    "                event_entity['props'].append(prop_object)\n",
    "\n",
    "\n",
    "    # empty, operation is solved by f above\n",
    "    def special_creation_event_label(self, operation, value, entity_mapper):\n",
    "        pass\n",
    "\n",
    "class ActionParser(Parser):\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        Parser.__init__(self, name, header_df, table_df, keyword_row_id, logger)\n",
    "\n",
    "\n",
    "class ConceptParser(Parser):\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        Parser.__init__(self, name, header_df, table_df, keyword_row_id, logger)\n",
    "\n",
    "    def special_wordnet_synset_id(self, operation, value, entity_mapper,field_name=\"special_wordnet_synset_id\",):\n",
    "        # wordnet_resource_id = R0067\n",
    "        entity_mapper.hook_ref_object(ref_legacyID = \"R0067\", input_value = value, origin = operation['operation'] +\">\"+ \":\"+field_name + \" \" +str(value))\n",
    "\n",
    "\n",
    "class ManuscriptParser(Parser):\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        Parser.__init__(self, name, header_df, table_df, keyword_row_id, logger)\n",
    "\n",
    "    def special_creation_event_id(self, operation, value, entity_mapper : EntityMapper, field_name=\"creation_event_id\"):\n",
    "        # Create entities in this col. as new E entities, with (1) the value here as legacy_id, (2) assign (as usual) a new “hash” ID from the db, (3) label of this E: see next col., (4) logical type “definite” (default), (5) label language “English”, (6) status “approved”, and (7) attach to any of those Es the metaprop \"(has) - C0565 “class” - C2642 “creation” (to instantiate the event to its event type = event class).\n",
    "\n",
    "        data = entity_mapper.data_row\n",
    "        event_entity = entity_mapper.make_eentity(data['creation_event_label'], legacyId = value)\n",
    "\n",
    "        prop_type_id = entity_mapper.get_entity_id(\"C0565\")\n",
    "        prop_value_id = entity_mapper.get_entity_id(\"C2642\")\n",
    "\n",
    "        # make IProp object\n",
    "        prop_object = entity_mapper.make_prop_object(prop_type_id, prop_value_id)\n",
    "\n",
    "\n",
    "        # hook prop object to the event entity\n",
    "        event_entity['props'].append(prop_object)\n",
    "\n",
    "        # hook the vent event to the territory\n",
    "        entity_mapper.hook_prop_object(prop_type = \"C2642\", input_value = event_entity['id'], origin = operation['operation'] +\">\"+ \":\"+field_name + str(value))\n",
    "\n",
    "        # process time_relations\n",
    "        t_relations = [(\n",
    "            data[\"timerelation1_type_conceptified_id\"], data[\"timerelation1_target_id\"]\n",
    "        ), (\n",
    "            data[\"timerelation2_type_conceptified_id\"], data[\"timerelation2_target_id\"]\n",
    "        ),(\n",
    "            data[\"timerelation3_type_conceptified_id\"], data[\"timerelation3_target_id\"]\n",
    "        ), (\n",
    "            data[\"timerelation4_type_conceptified_id\"], data[\"timerelation4_target_id\"]\n",
    "        )]\n",
    "\n",
    "        origin = data['legacyId']\n",
    "        for o in t_relations:\n",
    "            if len(o[0]) > 0 and len(o[1]) > 0:\n",
    "                prop_type_id = entity_mapper.get_entity_id(o[0], origin = origin)\n",
    "                prop_value_id = entity_mapper.get_entity_id(\"~V~\"+o[1], origin = origin)\n",
    "                prop_object = entity_mapper.make_prop_object(prop_type_id, prop_value_id)\n",
    "                event_entity['props'].append(prop_object)\n",
    "\n",
    "\n",
    "    # empty, operation is solved by f above\n",
    "    def special_creation_event_label(self, operation, value, entity_mapper):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def special_repository_label(self, operation, value, entity_mapper, field_name = \"repository_label\"):\n",
    "        # For each non-empty, non-NA, non-NS row: (1) generate L entity with label = value in this col., status = “approved”, entity logical type = “definite”, label language = value in the next col. (repository_label_language); (2) append to this L entity a metaprop (has) - C0565 “class” - C2646 “archive or library”, and (3) under the O entity representing the row (i.e. the physical manuscript), add a metaprop which will relate this O to this L entity (repository) through the relation: O - (has) - C2645 “repository” - L in this col.\n",
    "\n",
    "        origin = f\"Making location '{value}' from \" + entity_mapper.data_row['legacyId'] + \" by field {field_name}.\"\n",
    "\n",
    "        if value != \"\" and value!=\"NA\" and value!=\"N/A\" and value!=\"NS\":  # check value\n",
    "            lentity = entity_mapper.make_lentity(label=value, legacyId=\"L_from_\"+entity_mapper.data_row['legacyId'], origin=origin)\n",
    "\n",
    "            lentity['language'] = entity_mapper.enum_mapper['language'][entity_mapper.data_row['repository_label_language']]\n",
    "\n",
    "            prop_type_id = entity_mapper.get_entity_id(\"C0565\", origin = origin)\n",
    "            prop_value_id = entity_mapper.get_entity_id(\"C2646\", origin = origin)\n",
    "            prop_object = entity_mapper.make_prop_object(prop_type_id, prop_value_id)\n",
    "            lentity['props'].append(prop_object)\n",
    "\n",
    "            # let the manuscript O own the location\n",
    "            entity_mapper.hook_prop_object(prop_type = \"C2645\", input_value = lentity['id'], origin = origin)\n",
    "\n",
    "    # solves the method above\n",
    "    def special_repository_label_language(self, operation, value, entity_mapper):\n",
    "        pass\n",
    "\n",
    "    def special_reproduction_online_url(self, operation, value, entity_mapper, field_name = \"reproduction_online_url\"):\n",
    "        # If non-empty, non-NA, (1) generate an R entity with label \"Reproduction of \" + label of the MS (i.e. value in the B column, status = “approved”, label-language = “English”, url = the URL sitting under the hyperlink value in this cell, and (2) add metaprop to the O entity represented by this row: O - (has) - C1199 “digital reproduction” - the R entity here generated.\n",
    "\n",
    "        origin = f\"Making Resource entity '{value}' from \" + entity_mapper.data_row['legacyId'] + f\" by field {field_name}.\"\n",
    "\n",
    "        if value != \"\" and value!=\"NA\" and value!=\"N/A\" and value!=\"NS\":  # check value\n",
    "\n",
    "            if \"|\" in value:\n",
    "                data = value.split(\"|\")\n",
    "                label = data[0]\n",
    "                url = data[1]\n",
    "            else:\n",
    "                url = \"\"\n",
    "                label = value\n",
    "                logger.warning(f\"Expected char | signaling url after label. Got just {value}. \"+origin)\n",
    "\n",
    "            rentity = entity_mapper.make_rentity(label, url, origin=origin)\n",
    "            entity_mapper.hook_prop_object(prop_type = \"C1199\", input_value = rentity['id'], origin = origin)\n",
    "\n",
    "\n",
    "class ResourceParser(Parser):\n",
    "\n",
    "    def __init__(self, name, header_df: pd.DataFrame, table_df: pd.DataFrame, keyword_row_id: int, logger: logger):\n",
    "        Parser.__init__(self, name, header_df, table_df, keyword_row_id, logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:53:35,385 INFO Start\n",
      "2022-04-03 10:53:35,392 INFO TEXTS Uncertain parsing instructions in 0 columns: .\n",
      "2022-04-03 10:53:35,394 INFO TEXTS 66 columns have been dropped (discard:66, unknown:0). Table now has 50 columns, inside:9,propvalue:14, special:5, proptype: 4, dependent:4. Originally 116 columns.\n",
      "2022-04-03 10:53:35,398 INFO MANUSCRIPTS Uncertain parsing instructions in 0 columns: .\n",
      "2022-04-03 10:53:35,400 INFO MANUSCRIPTS 35 columns have been dropped (discard:35, unknown:0). Table now has 30 columns, inside:8,propvalue:9, special:5, proptype: 4, dependent:4. Originally 65 columns.\n",
      "2022-04-03 10:53:35,402 INFO RESOURCES Uncertain parsing instructions in 0 columns: .\n",
      "2022-04-03 10:53:35,403 INFO RESOURCES 14 columns have been dropped (discard:14, unknown:0). Table now has 10 columns, inside:6,propvalue:2, special:0, proptype: 0, dependent:0. Originally 24 columns.\n",
      "2022-04-03 10:53:35,407 INFO CONCEPTS Uncertain parsing instructions in 0 columns: .\n",
      "2022-04-03 10:53:35,411 INFO CONCEPTS 49 columns have been dropped (discard:48, unknown:1). Table now has 18 columns, inside:8,propvalue:8, special:2, proptype: 0, dependent:0. Originally 67 columns.\n",
      "2022-04-03 10:53:35,421 INFO ACTIONS Uncertain parsing instructions in 0 columns: .\n",
      "2022-04-03 10:53:35,424 INFO ACTIONS 52 columns have been dropped (discard:51, unknown:1). Table now has 26 columns, inside:15,propvalue:11, special:0, proptype: 0, dependent:0. Originally 78 columns.\n",
      "2022-04-03 10:53:35,443 INFO Starting to parse texts.\n",
      "2022-04-03 10:53:53,287 INFO Starting to parse manuscripts.\n",
      "2022-04-03 10:53:57,152 WARNING Expected char | signaling url after label. Got just part. Making Resource entity 'part' from M19 by field reproduction_online_url.\n",
      "2022-04-03 10:53:59,896 WARNING Expected char | signaling url after label. Got just ?. Making Resource entity '?' from M79 by field reproduction_online_url.\n",
      "2022-04-03 10:54:09,688 WARNING Expected char | signaling url after label. Got just link. Making Resource entity 'link' from M121 by field reproduction_online_url.\n",
      "2022-04-03 10:54:09,841 WARNING Expected char | signaling url after label. Got just link. Making Resource entity 'link' from M122 by field reproduction_online_url.\n",
      "2022-04-03 10:54:09,999 WARNING Expected char | signaling url after label. Got just link. Making Resource entity 'link' from M123 by field reproduction_online_url.\n",
      "2022-04-03 10:54:10,196 WARNING Expected char | signaling url after label. Got just link. Making Resource entity 'link' from M124 by field reproduction_online_url.\n",
      "2022-04-03 10:54:10,399 WARNING Expected char | signaling url after label. Got just link. Making Resource entity 'link' from M125 by field reproduction_online_url.\n",
      "2022-04-03 10:54:14,759 INFO Starting to parse resources.\n",
      "2022-04-03 10:54:14,761 INFO Empty labels found in resources table. (new entities added through parsing process). Adjusting.\n",
      "2022-04-03 10:54:16,922 INFO Starting to parse concepts.\n",
      "2022-04-03 10:55:48,390 INFO Starting to parse actions.\n",
      "2022-04-03 10:56:14,934 INFO End\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Start\")\n",
    "cp = ParseController(entity_list=['texts','manuscripts','resources','concepts','actions'])\n",
    "# cp = ParseController(entity_list=['resources'])\n",
    "cp.parse()\n",
    "logger.info(f\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#%reload_ext line_profiler\n",
    "\n",
    "# def profile():\n",
    "#    cp.parsers['concepts'].parse_rows()\n",
    "\n",
    "#%lprun -f EntityMapper.get_entity_id profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %prun -s tottime profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %lprun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "                                       id  \\\n0    5526ffbd-486d-445d-8c7a-4dd15acbe7d8   \n1    f6290002-050d-4d72-9f80-4902a5c4a26a   \n2    e0522c0a-59e3-46d4-b793-4e4133c34bde   \n3    38528e5f-855c-4457-a149-90c43cac7507   \n4    4aa68b7d-471f-464f-8319-815536ff0a54   \n..                                    ...   \n276  eba5c362-80e6-4cca-a9ea-e6ccfb7c1582   \n277  9f4ea920-b74a-4729-9a5d-6210dbd8cbf3   \n278  5568f736-d4b2-442d-a759-79be88723443   \n279  9b5babb2-258d-47a1-87c3-9cdcfea4b0e1   \n280  98596171-4694-4953-96ec-2531a4efcb1e   \n\n                                                 value origin    legacyId  \n0    Creation of \"Process against Bernard Niort and...           E0001_T1  \n1    Creation of 'Sentences of William Arnold and S...           E0002_T2  \n2     Creation of 'Peter Seila’s Register of Penances'           E0003_T3  \n3    Creation of 'Register FFF of the Carcassonne i...           E0004_T4  \n4    Creation of 'Confirmation of depositions befor...           E0005_T5  \n..                                                 ...    ...         ...  \n276  Creation of manuscript St Paul-im-Lavanttal, S...         E0135_M153  \n277  Creation of manuscript codex Roma, Biblioteca ...         E0136_M154  \n278  Creation of manuscript codex Roma, Archivio Ge...         E0137_M155  \n279  Creation of manuscript codex Wien, Österreichi...         E0138_M156  \n280  Creation of multi-volume collection Paris, Bib...         E0139_M157  \n\n[281 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>value</th>\n      <th>origin</th>\n      <th>legacyId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5526ffbd-486d-445d-8c7a-4dd15acbe7d8</td>\n      <td>Creation of \"Process against Bernard Niort and...</td>\n      <td></td>\n      <td>E0001_T1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f6290002-050d-4d72-9f80-4902a5c4a26a</td>\n      <td>Creation of 'Sentences of William Arnold and S...</td>\n      <td></td>\n      <td>E0002_T2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e0522c0a-59e3-46d4-b793-4e4133c34bde</td>\n      <td>Creation of 'Peter Seila’s Register of Penances'</td>\n      <td></td>\n      <td>E0003_T3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38528e5f-855c-4457-a149-90c43cac7507</td>\n      <td>Creation of 'Register FFF of the Carcassonne i...</td>\n      <td></td>\n      <td>E0004_T4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4aa68b7d-471f-464f-8319-815536ff0a54</td>\n      <td>Creation of 'Confirmation of depositions befor...</td>\n      <td></td>\n      <td>E0005_T5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>eba5c362-80e6-4cca-a9ea-e6ccfb7c1582</td>\n      <td>Creation of manuscript St Paul-im-Lavanttal, S...</td>\n      <td></td>\n      <td>E0135_M153</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>9f4ea920-b74a-4729-9a5d-6210dbd8cbf3</td>\n      <td>Creation of manuscript codex Roma, Biblioteca ...</td>\n      <td></td>\n      <td>E0136_M154</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>5568f736-d4b2-442d-a759-79be88723443</td>\n      <td>Creation of manuscript codex Roma, Archivio Ge...</td>\n      <td></td>\n      <td>E0137_M155</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>9b5babb2-258d-47a1-87c3-9cdcfea4b0e1</td>\n      <td>Creation of manuscript codex Wien, Österreichi...</td>\n      <td></td>\n      <td>E0138_M156</td>\n    </tr>\n    <tr>\n      <th>280</th>\n      <td>98596171-4694-4953-96ec-2531a4efcb1e</td>\n      <td>Creation of multi-volume collection Paris, Bib...</td>\n      <td></td>\n      <td>E0139_M157</td>\n    </tr>\n  </tbody>\n</table>\n<p>281 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables['events']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "     class                                    id label language detail  \\\n0        V  edda2d72-471c-412f-be6d-2d7d38365f16     *                   \n1        V  2a98510b-3238-4ac6-99f0-a5049827a9c3     *                   \n2        V  4aff2a63-30e9-42ca-9907-1a828f8cd059     *                   \n3        V  f0c5d0c1-18fe-4249-b449-2930269da82a     *                   \n4        V  2ba63bec-bc3f-4ee2-b3bf-d20d80e758ef     *                   \n...    ...                                   ...   ...      ...    ...   \n1865     V  1f97529c-ab60-45b7-9ed1-90ad02d6ce08   ???                   \n1866     V  9d267bbf-586c-4d86-b86b-6d54292bf9ca   ???                   \n1867     V  dba15152-e37d-4e74-9b6e-b1d0c83bbf24   ???                   \n1868     V  e5929922-6c80-4fda-a7f1-81183a0c0b33   ???                   \n1869     V  4ef2a8bc-5374-4c3b-9222-50e58fa667cf   ???                   \n\n                      data props  \\\n0     {'logicalType': '4'}    []   \n1     {'logicalType': '4'}    []   \n2     {'logicalType': '4'}    []   \n3     {'logicalType': '4'}    []   \n4     {'logicalType': '4'}    []   \n...                    ...   ...   \n1865  {'logicalType': '4'}    []   \n1866  {'logicalType': '4'}    []   \n1867  {'logicalType': '4'}    []   \n1868  {'logicalType': '4'}    []   \n1869  {'logicalType': '4'}    []   \n\n                                                  notes status references  \\\n0     [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n1     [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n2     [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n3     [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n4     [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n...                                                 ...    ...        ...   \n1865  [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n1866  [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n1867  [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n1868  [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n1869  [Import batch 2022-04-02 23:28:10.114166, Impo...      1         []   \n\n     legacyId  \n0         NaN  \n1         NaN  \n2         NaN  \n3         NaN  \n4         NaN  \n...       ...  \n1865      NaN  \n1866      NaN  \n1867      NaN  \n1868      NaN  \n1869      NaN  \n\n[1870 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>id</th>\n      <th>label</th>\n      <th>language</th>\n      <th>detail</th>\n      <th>data</th>\n      <th>props</th>\n      <th>notes</th>\n      <th>status</th>\n      <th>references</th>\n      <th>legacyId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V</td>\n      <td>edda2d72-471c-412f-be6d-2d7d38365f16</td>\n      <td>*</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V</td>\n      <td>2a98510b-3238-4ac6-99f0-a5049827a9c3</td>\n      <td>*</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V</td>\n      <td>4aff2a63-30e9-42ca-9907-1a828f8cd059</td>\n      <td>*</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V</td>\n      <td>f0c5d0c1-18fe-4249-b449-2930269da82a</td>\n      <td>*</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V</td>\n      <td>2ba63bec-bc3f-4ee2-b3bf-d20d80e758ef</td>\n      <td>*</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1865</th>\n      <td>V</td>\n      <td>1f97529c-ab60-45b7-9ed1-90ad02d6ce08</td>\n      <td>???</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1866</th>\n      <td>V</td>\n      <td>9d267bbf-586c-4d86-b86b-6d54292bf9ca</td>\n      <td>???</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1867</th>\n      <td>V</td>\n      <td>dba15152-e37d-4e74-9b6e-b1d0c83bbf24</td>\n      <td>???</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1868</th>\n      <td>V</td>\n      <td>e5929922-6c80-4fda-a7f1-81183a0c0b33</td>\n      <td>???</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1869</th>\n      <td>V</td>\n      <td>4ef2a8bc-5374-4c3b-9222-50e58fa667cf</td>\n      <td>???</td>\n      <td></td>\n      <td></td>\n      <td>{'logicalType': '4'}</td>\n      <td>[]</td>\n      <td>[Import batch 2022-04-02 23:28:10.114166, Impo...</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1870 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is this d72b2bee-47b4-4abc-8c88-793c72ab676d ?\n",
    "\n",
    "pd.DataFrame(additional_entities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Last checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class\": \"A\", \"id\": \"b3d223b5-5cf3-4f7e-8ec8-3f4a291355fa\", \"legacyId\": \"A0168\", \"label\": \"abiurationem recepit\", \"language\": \"lat\", \"detail\": \"received abjuration (from sb)\", \"data\": {\"entities\": {\"a1\": [\"P\", \"G\"], \"a2\": [\"NULL\"], \"s\": [\"P\", \"G\"]}, \"valencies\": {\"a1\": \"\\\"a\\\" + 6 | 2\", \"a2\": \"NULL\", \"s\": \"1\"}}, \"props\": [{\"bundleEnd\": false, \"bundleStart\": false, \"certainty\": \"1\", \"children\": [], \"elvl\": \"1\", \"id\": \"bd8727c7-23c1-4d3e-8334-c5678e9e1a37\", \"logic\": \"1\", \"mood\": [], \"moodvariant\": \"1\", \"bundleOperator\": \"=\", \"type\": {\"id\": \"5228b299-d77a-41e1-bbff-c5602eda74d0\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}, \"value\": {\"id\": \"dac22c9c-4731-4da5-8b7b-14fc821fe199\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}}, {\"bundleEnd\": false, \"bundleStart\": false, \"certainty\": \"1\", \"children\": [], \"elvl\": \"1\", \"id\": \"983f87cf-88e7-476e-bb73-899c7c30f351\", \"logic\": \"1\", \"mood\": [], \"moodvariant\": \"1\", \"bundleOperator\": \"=\", \"type\": {\"id\": \"b2ae78a5-6296-4fe1-874e-2baab326af14\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}, \"value\": {\"id\": \"295fa2c7-b14b-4570-9ea3-8de1361ce202\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}}, {\"bundleEnd\": false, \"bundleStart\": false, \"certainty\": \"1\", \"children\": [], \"elvl\": \"1\", \"id\": \"bf38efa0-d16e-456d-b640-61e979e305b6\", \"logic\": \"1\", \"mood\": [], \"moodvariant\": \"1\", \"bundleOperator\": \"=\", \"type\": {\"id\": \"00f495db-c0e6-46be-bea6-ea33d7bd17b9\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}, \"value\": {\"id\": \"30f399f1-8cc2-4bf1-aa4a-300a134d5dae\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}}, {\"bundleEnd\": false, \"bundleStart\": false, \"certainty\": \"1\", \"children\": [], \"elvl\": \"1\", \"id\": \"a90b3d22-dd78-4732-9dda-c5e7793fb4c4\", \"logic\": \"1\", \"mood\": [], \"moodvariant\": \"1\", \"bundleOperator\": \"=\", \"type\": {\"id\": \"e3b9d8ec-cd10-4b00-8029-971885679e1d\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}, \"value\": {\"id\": \"7955d11f-aea5-46cb-8066-64bbea2275d9\", \"elvl\": \"1\", \"logic\": \"1\", \"partitivity\": \"1\", \"virtuality\": \"1\"}}], \"notes\": [\"Import batch [development] 2022-04-03 10:35:54.053061\"], \"status\": \"1\", \"references\": []}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(cp.parsers['actions'].js_objects[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 10:59:31,174 INFO There are 1865 additionally created entities (e.g. values, resources ...).\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"There are {len(additional_entities)} additionally created entities (e.g. values, resources ...).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Output the parsed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# root data\n",
    "root_territory = \"\"\"\n",
    " {\n",
    "    \"id\": \"T0\",\n",
    "    \"class\": \"T\",\n",
    "    \"data\": { \"parent\": false },\n",
    "    \"label\": \"everything\",\n",
    "    \"detail\": \"\",\n",
    "    \"language\": \"lat\",\n",
    "    \"notes\": [],\n",
    "    \"props\": []\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# connects outcomes from the individual parsers\n",
    "cp.load_json_objects()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-03 11:00:04,572 INFO END\n"
     ]
    }
   ],
   "source": [
    "# save json object list of the parsed entities from google sheets in the text file\n",
    "with open('../datasets/all-test/new_entities.json', 'w', encoding='utf-8') as f:\n",
    "    #f.write(str(cp.parsers['texts'].js_objects))\n",
    "    json.dump(cp.js_objects, f)\n",
    "\n",
    "# save json object list of the \"newly created entities\" in the text file\n",
    "with open('../datasets/all-test/additional_entities.json', 'w', encoding='utf-8') as f:\n",
    "    #f.write(str(cp.parsers['texts'].js_objects))\n",
    "    json.dump(additional_entities, f)\n",
    "\n",
    "# read  entities.json\n",
    "with open('../datasets/all/entities.json','r') as f:\n",
    "    #entities_content = f.readlines()\n",
    "    entities_content = f.read().replace('\\n', '')\n",
    "\n",
    "# read  entities.json\n",
    "with open('../datasets/all-test/new_entities.json','r') as f:\n",
    "    #entities_content = f.readlines()\n",
    "    new_entities_content = f.read().replace('\\n', '')\n",
    "\n",
    "additional_entities_string = json.dumps(additional_entities)\n",
    "\n",
    "# write new and combine with old test data\n",
    "with open('../datasets/all-test/entities.json','w', encoding='utf-8') as f:\n",
    "    #merge_content = entities_content[0:-1] +  str(cp.parsers['texts'].js_objects)[1:]\n",
    "    merge_content = entities_content[0:-1] +\", \" + additional_entities_string[1:-1]+ \", \" + new_entities_content[1:]\n",
    "    f.write(str(merge_content))\n",
    "\n",
    "\n",
    "\n",
    "# write just the new parse data to the entities json.\n",
    "with open('../datasets/all-parsed/entities.json','w', encoding='utf-8') as f:\n",
    "    #merge_content = entities_content[0:-1] +  str(cp.parsers['texts'].js_objects)[1:]\n",
    "    merge_content =  \"[\" + root_territory + \",\" + additional_entities_string[1:-1]+ \", \" + new_entities_content[1:]\n",
    "    f.write(str(merge_content))\n",
    "\n",
    "logger.info(\"END\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}